{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.idle": "2025-07-27T07:52:39.640919Z",
     "shell.execute_reply": "2025-07-27T07:52:39.640015Z",
     "shell.execute_reply.started": "2025-07-27T07:49:32.173353Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Already processed: 3425524 reviews\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885fbbc6caa34f76994e65f61bce433b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed:   0%|          | 0/3431734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33030dfba8ee4d14ae54e66da10cc93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skipped: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import csv\n",
    "\n",
    "\n",
    "all_labels = [\n",
    "    'cleanliness', 'cozy_atmosphere', 'delicious_food', 'dirty', 'fresh_ingredients', 'friendly_staff', 'good_value', 'low_quality_ingredients', 'negative', 'noisy_environment', 'overcooked', 'overpriced', 'poor_taste', 'positive', 'professional_service', 'rude_staff', 'slow_service', 'spoiled', 'unhygienic', 'unprofessional_service'\n",
    "]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU will be used\")\n",
    "\n",
    "# Modell auf CUDA, wenn vorhanden\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\" Verwende Ger√§t:\", device)\n",
    "\n",
    "#  Funktion: Vorhersage f√ºr langen Text mit Chunking\n",
    "def predict_labels_for_long_text(text, chunk_size=256):\n",
    "    #  Tokenisieren (ohne Abschneiden)\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\", truncation=False)\n",
    "    input_ids = encoded[\"input_ids\"][0]\n",
    "\n",
    "    #  In Chunks aufteilen\n",
    "    all_preds = []\n",
    "    for i in range(0, len(input_ids), chunk_size):\n",
    "        chunk_ids = input_ids[i:i+chunk_size]\n",
    "        chunk_inputs = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "        \n",
    "        inputs = tokenizer(chunk_inputs, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=chunk_size)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}  # Auf GPU verschieben\n",
    "\n",
    "        # inputs = tokenizer(chunk_inputs, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=chunk_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "            preds = (probs > 0.75).astype(int)\n",
    "            all_preds.append(preds)\n",
    "\n",
    "    # Aggregation: wenn ein Label in einem Chunk vorkommt, nehmen wir es insgesamt\n",
    "    final_preds = np.max(np.array(all_preds), axis=0)\n",
    "    predicted_labels = [label for label, flag in zip(all_labels, final_preds) if flag == 1]\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "#  Hauptfunktion ‚Äì liest die richtige Datei basierend auf Start & End\n",
    "def main():\n",
    "    #  Eingabe & Ausgabe-Dateien anhand der Parameter\n",
    "    input_file = f\"/kaggle/input/dish-dash/reviews/reviews.csv\"\n",
    "    output_file = f\"/kaggle/working/review_label.csv\"\n",
    "\n",
    "    # Modell & Tokenizer laden\n",
    "    global tokenizer, model\n",
    "    MODEL_PATH = \"/kaggle/input/dish-dash/final_model_70k/final_model_70k\"\n",
    "\n",
    "\n",
    "\n",
    "# Modell laden mit CUDA\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "    #  CSV-Datei komplett laden\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    processed_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        existing_df = pd.read_csv(output_file)\n",
    "        processed_ids = set(existing_df['review_id'].astype(str).tolist())\n",
    "        print(f\" Already processed: {len(processed_ids)} reviews\")\n",
    "\n",
    "    \n",
    "\n",
    "    total = len(df)\n",
    "    # Create two progress bars\n",
    "    progress_bar = tqdm(total=total, desc=\"Processed\")\n",
    "    skipped_bar = tqdm(total=0, desc=\"Skipped\", position=1)\n",
    "    \n",
    "    df = df[df['review_id'].isin(processed_ids)==False]\n",
    "    progress_bar.update(len(processed_ids))\n",
    "\n",
    "    #  CSV-Ausgabe initialisieren\n",
    "    with open(output_file, mode='a' if os.path.exists(output_file) else 'w', newline='', encoding='utf-8') as out_csv:\n",
    "        writer = csv.writer(out_csv)\n",
    "        if not os.path.exists(output_file):  # Header nur einmal schreiben\n",
    "            writer.writerow(['review_id', 'label'])\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            review_id = row['review_id']\n",
    "            text = row['text']\n",
    "\n",
    "            labels = predict_labels_for_long_text(text)\n",
    "\n",
    "            #  Jede Label-Zeile separat speichern\n",
    "            for label in labels:\n",
    "                writer.writerow([review_id, label])\n",
    "            \n",
    "            if len(labels)==0:\n",
    "                skipped_bar.total += 1\n",
    "                skipped_bar.update(1)\n",
    "                skipped_bar.refresh()\n",
    "                \n",
    "            progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "    skipped_bar.close()\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7946872,
     "sourceId": 12582686,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
